{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860001/860001 [25:18<00:00, 566.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO-2017 dataset has been successfully converted to TensorFlow ImageFolder dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "coco_path = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\train'\n",
    "output_path = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\tensorflow_dataset'\n",
    "\n",
    "# Load annotations\n",
    "with open(os.path.join(coco_path, 'labels.json')) as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Create class directories\n",
    "categories = {cat['id']: cat['name'] for cat in annotations['categories']}\n",
    "for cat in categories.values():\n",
    "    os.makedirs(os.path.join(output_path, 'train', cat), exist_ok=True)\n",
    "\n",
    "# Move images to class directories\n",
    "for ann in tqdm(annotations['annotations']):\n",
    "    img_id = ann['image_id']\n",
    "    cat_id = ann['category_id']\n",
    "    img_name = f'{img_id:012d}.jpg'\n",
    "    src_path = os.path.join(coco_path, 'data', img_name)\n",
    "    dst_path = os.path.join(output_path, 'train', categories[cat_id], img_name)\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(\"COCO-2017 dataset has been successfully converted to TensorFlow ImageFolder dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving train images: 100%|██████████| 602000/602000 [26:44<00:00, 375.28it/s]  \n",
      "Moving validation images: 100%|██████████| 129000/129000 [06:09<00:00, 348.85it/s]\n",
      "Moving test images: 100%|██████████| 129001/129001 [06:06<00:00, 351.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO-2017 dataset has been successfully split into train, validation, and test sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "coco_path = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\train'\n",
    "output_path = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\tensorflow_dataset'\n",
    "\n",
    "# Load annotations\n",
    "with open(os.path.join(coco_path, 'labels.json')) as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Create class directories for train, validation, and test\n",
    "categories = {cat['id']: cat['name'] for cat in annotations['categories']}\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for cat in categories.values():\n",
    "        os.makedirs(os.path.join(output_path, split, cat), exist_ok=True)\n",
    "\n",
    "# Split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Shuffle and split the annotations\n",
    "random.shuffle(annotations['annotations'])\n",
    "total_annotations = len(annotations['annotations'])\n",
    "train_end = int(train_ratio * total_annotations)\n",
    "val_end = int((train_ratio + val_ratio) * total_annotations)\n",
    "\n",
    "train_annotations = annotations['annotations'][:train_end]\n",
    "val_annotations = annotations['annotations'][train_end:val_end]\n",
    "test_annotations = annotations['annotations'][val_end:]\n",
    "\n",
    "# Function to move images to the respective directories\n",
    "def move_images(annotations, split):\n",
    "    for ann in tqdm(annotations, desc=f'Moving {split} images'):\n",
    "        img_id = ann['image_id']\n",
    "        cat_id = ann['category_id']\n",
    "        img_name = f'{img_id:012d}.jpg'\n",
    "        src_path = os.path.join(coco_path, 'data', img_name)\n",
    "        dst_path = os.path.join(output_path, split, categories[cat_id], img_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "# Move images to the respective directories\n",
    "move_images(train_annotations, 'train')\n",
    "move_images(val_annotations, 'validation')\n",
    "move_images(test_annotations, 'test')\n",
    "\n",
    "print(\"COCO-2017 dataset has been successfully split into train, validation, and test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "train_dir = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\tensorflow_dataset\\\\train'\n",
    "val_dir = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\tensorflow_dataset\\\\validation'\n",
    "test_dir = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\tensorflow_dataset\\\\test'\n",
    "\n",
    "# Image data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Get true labels and predictions\n",
    "test_generator.reset()\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Classification report\n",
    "print('Classification Report')\n",
    "print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))\n",
    "\n",
    "# Confusion matrix\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 342996 images belonging to 80 classes.\n",
      "Found 95879 images belonging to 80 classes.\n",
      "Found 95894 images belonging to 80 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m10719/10719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4586s\u001b[0m 427ms/step - accuracy: 0.2625 - loss: 2.6706 - val_accuracy: 0.3151 - val_loss: 2.3428\n",
      "Epoch 2/10\n",
      "\u001b[1m10719/10719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4029s\u001b[0m 376ms/step - accuracy: 0.2814 - loss: 2.4755 - val_accuracy: 0.3331 - val_loss: 2.2944\n",
      "Epoch 3/10\n",
      "\u001b[1m10719/10719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3946s\u001b[0m 368ms/step - accuracy: 0.2854 - loss: 2.4425 - val_accuracy: 0.3210 - val_loss: 2.2690\n",
      "Epoch 4/10\n",
      "\u001b[1m10719/10719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4532s\u001b[0m 423ms/step - accuracy: 0.2863 - loss: 2.4228 - val_accuracy: 0.3270 - val_loss: 2.2444\n",
      "Epoch 5/10\n",
      "\u001b[1m10719/10719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4054s\u001b[0m 378ms/step - accuracy: 0.2861 - loss: 2.4039 - val_accuracy: 0.3289 - val_loss: 2.2410\n",
      "\u001b[1m2997/2997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1246s\u001b[0m 416ms/step - accuracy: 0.3328 - loss: 2.2903\n",
      "Test Loss: 2.2829558849334717\n",
      "Test Accuracy: 0.3355267345905304\n",
      "\u001b[1m2997/2997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 296ms/step\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      airplane       0.01      0.02      0.01       712\n",
      "         apple       0.01      0.00      0.01       611\n",
      "      backpack       0.00      0.00      0.00      1189\n",
      "        banana       0.01      0.01      0.01       835\n",
      "  baseball bat       0.00      0.00      0.00       444\n",
      "baseball glove       0.00      0.00      0.00       494\n",
      "          bear       0.00      0.00      0.00       184\n",
      "           bed       0.00      0.01      0.00       595\n",
      "         bench       0.01      0.00      0.00      1216\n",
      "       bicycle       0.00      0.00      0.00       843\n",
      "          bird       0.01      0.01      0.01      1058\n",
      "          boat       0.02      0.02      0.02      1067\n",
      "          book       0.01      0.00      0.00      2258\n",
      "        bottle       0.03      0.01      0.02      2730\n",
      "          bowl       0.02      0.01      0.02      1804\n",
      "      broccoli       0.01      0.01      0.01       777\n",
      "           bus       0.00      0.00      0.00       823\n",
      "          cake       0.01      0.00      0.00       716\n",
      "           car       0.06      0.02      0.03      4667\n",
      "        carrot       0.02      0.01      0.01       787\n",
      "           cat       0.01      0.01      0.01       658\n",
      "    cell phone       0.01      0.00      0.00       897\n",
      "         chair       0.04      0.04      0.04      4157\n",
      "         clock       0.01      0.00      0.01       878\n",
      "         couch       0.00      0.00      0.00       842\n",
      "           cow       0.01      0.01      0.01       815\n",
      "           cup       0.02      0.01      0.01      2508\n",
      "  dining table       0.02      0.04      0.03      2176\n",
      "           dog       0.01      0.01      0.01       793\n",
      "         donut       0.00      0.01      0.00       651\n",
      "      elephant       0.01      0.01      0.01       629\n",
      "  fire hydrant       0.01      0.01      0.01       284\n",
      "          fork       0.01      0.00      0.00       770\n",
      "       frisbee       0.00      0.00      0.00       374\n",
      "       giraffe       0.00      0.01      0.01       660\n",
      "    hair drier       0.00      0.00      0.00        33\n",
      "       handbag       0.00      0.00      0.00      1568\n",
      "         horse       0.01      0.00      0.00       844\n",
      "       hot dog       0.00      0.00      0.00       327\n",
      "      keyboard       0.00      0.00      0.00       405\n",
      "          kite       0.01      0.00      0.00       856\n",
      "         knife       0.01      0.01      0.01      1017\n",
      "        laptop       0.01      0.01      0.01       663\n",
      "     microwave       0.00      0.00      0.00       267\n",
      "    motorcycle       0.01      0.02      0.01      1014\n",
      "         mouse       0.01      0.01      0.01       318\n",
      "        orange       0.00      0.00      0.00       634\n",
      "          oven       0.01      0.01      0.01       502\n",
      " parking meter       0.00      0.00      0.00       162\n",
      "        person       0.26      0.47      0.34     25124\n",
      "         pizza       0.01      0.01      0.01       723\n",
      "  potted plant       0.00      0.00      0.00      1073\n",
      "  refrigerator       0.00      0.01      0.01       370\n",
      "        remote       0.01      0.01      0.01       743\n",
      "      sandwich       0.01      0.01      0.01       550\n",
      "      scissors       0.00      0.00      0.00       188\n",
      "         sheep       0.01      0.01      0.01       805\n",
      "          sink       0.01      0.01      0.01       847\n",
      "    skateboard       0.01      0.01      0.01       750\n",
      "          skis       0.00      0.00      0.00       839\n",
      "     snowboard       0.00      0.00      0.00       347\n",
      "         spoon       0.02      0.00      0.00       855\n",
      "   sports ball       0.02      0.00      0.00       829\n",
      "     stop sign       0.00      0.00      0.00       260\n",
      "      suitcase       0.02      0.01      0.01       684\n",
      "     surfboard       0.00      0.00      0.00       789\n",
      "    teddy bear       0.00      0.00      0.00       520\n",
      " tennis racket       0.01      0.01      0.01       675\n",
      "           tie       0.00      0.00      0.00       814\n",
      "       toaster       0.00      0.00      0.00        30\n",
      "        toilet       0.00      0.00      0.00       561\n",
      "    toothbrush       0.00      0.00      0.00       269\n",
      " traffic light       0.02      0.01      0.02      1497\n",
      "         train       0.01      0.03      0.02       597\n",
      "         truck       0.01      0.01      0.01      1303\n",
      "            tv       0.01      0.00      0.01       837\n",
      "      umbrella       0.00      0.00      0.00      1225\n",
      "          vase       0.01      0.00      0.01       820\n",
      "    wine glass       0.00      0.00      0.00       836\n",
      "         zebra       0.01      0.01      0.01       622\n",
      "\n",
      "      accuracy                           0.13     95894\n",
      "     macro avg       0.01      0.01      0.01     95894\n",
      "  weighted avg       0.08      0.13      0.10     95894\n",
      "\n",
      "Confusion Matrix\n",
      "[[12  2  0 ...  4  0  8]\n",
      " [11  3  1 ...  4  0  6]\n",
      " [20  7  0 ...  5  2 11]\n",
      " ...\n",
      " [12  5  0 ...  3  0  9]\n",
      " [12  6  0 ...  4  0  4]\n",
      " [ 7  7  0 ...  3  1  5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xxnab\\OneDrive\\Documents\\GitHub\\FYP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\xxnab\\OneDrive\\Documents\\GitHub\\FYP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\xxnab\\OneDrive\\Documents\\GitHub\\FYP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "train_dir = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\tensorflow_dataset\\\\train'\n",
    "val_dir = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\tensorflow_dataset\\\\validation'\n",
    "test_dir = r'C:\\\\Users\\\\xxnab\\\\fiftyone\\\\coco-2017\\\\tensorflow_dataset\\\\test'\n",
    "\n",
    "# Image data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Get true labels and predictions\n",
    "test_generator.reset()\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Classification report\n",
    "print('Classification Report')\n",
    "print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))\n",
    "\n",
    "# Confusion matrix\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
